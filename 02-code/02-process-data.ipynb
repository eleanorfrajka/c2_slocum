{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "428ca4b2-e930-4925-ba9e-7d77d5fcd896",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Script to download glider (slocum) data from the C2/API web services at NOC MARS.  \n",
    "\n",
    "1. Works locally on the downloaded raw netcdf files.\n",
    "2. Calculate MLD\n",
    "3. Calculate oxygen\n",
    "\n",
    "\n",
    "Runs offline, using the netcdf files created in update_raw_data.py\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f67044f0-59d7-4f4b-8267-405124a756d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import datetime as dt\n",
    "import requests\n",
    "import json\n",
    "from io import StringIO\n",
    "import ast # To handle the string conversion when loading json filee\n",
    "from pathlib import Path\n",
    "# Own packages of code\n",
    "from setdir import *\n",
    "from parseglider import *\n",
    "from plotglider import *\n",
    "from calc_oxy import *\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cdfed1b-02ee-404d-874f-9ee2dcbbd9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choice of grid interval (pressure in dbar)\n",
    "dp=10\n",
    "\n",
    "## CHANGE TO A CONFIG FILE WITH USER DEFINABLE PARAMETERS\n",
    "# Slocum gliders: A dictionary with the key as the serial number ('unit_398') \n",
    "# and then the plain text name, \"Churchill\"\n",
    "glider_names = {\n",
    "    'unit_398': 'Churchill',\n",
    "    'unit_409': 'Grease',\n",
    "}\n",
    "\n",
    "sensor_sn = {\n",
    "    'unit_398': {\"optode SN\": \"232\"},\n",
    "    'unit_409': {\"optode SN\": \"268\"},\n",
    "}\n",
    "# Dictionary keys MUST match the serial number format used in the API.  \n",
    "\n",
    "# List of glider serial numbers for API\n",
    "unit_list = [(k) for k in glider_names.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d9a8036-e30f-42f3-9f1a-154282cd3c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing it\n",
      "Doing it\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------\n",
    "# DATA PROCESSING:\n",
    "# - Calculate oxygen\n",
    "#\n",
    "# Save new files to 01-data/03-interim/ as\n",
    "#   UNIT_data_YYYYMMDD.nc for the full data as a vector\n",
    "#   UNIT_bin10m.nc for the rough gridded data.\n",
    "#--------------------------------------------------------------\n",
    "for uname in unit_list:\n",
    "    fname = uname+'*_data.nc'\n",
    "    \n",
    "    # Extract a list with the names of existing raw data files\n",
    "    existing_files = glob.glob(cat_interim_path(fname))\n",
    "    \n",
    "    # Check whether there are any files\n",
    "    if len(existing_files) > 0:\n",
    "        # Extract the most recent filename\n",
    "        existing_files = sorted(existing_files)\n",
    "        latest_file = existing_files[-1]\n",
    "        \n",
    "        # Open the dataset\n",
    "        data_ds = xr.open_dataset(latest_file)\n",
    "        \n",
    "        #--------------------------------------------------------------\n",
    "        # Calculate oxygen (maybe this should be elsewhere)\n",
    "        # but I need it before gridding (or need a function to grid\n",
    "        # individual extra variables)\n",
    "        #--------------------------------------------------------------\n",
    "        sensorsn1 = sensor_sn[uname]\n",
    "        data_ds = data_ds.assign_attrs(sensorsn1)\n",
    "        data_ds = calc_o2conc_cal(data_ds)\n",
    "        print('Doing it')\n",
    "        fname2 = latest_file[0:-3]+'_o2.nc'\n",
    "\n",
    "        # Add oxygen to the file and save it to the same path (interim)\n",
    "        # Save updated with oxygen\n",
    "        data_ds.to_netcdf(fname2, mode='w')\n",
    "        data_ds.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2540824e-1dce-4b63-8c48-b3b0b61cda84",
   "metadata": {},
   "outputs": [],
   "source": [
    "glider_names = {\n",
    "    'unit_409': 'Grease',\n",
    "}\n",
    "\n",
    "\n",
    "glider_names = {\n",
    "    'unit_398': 'Churchill',\n",
    "}\n",
    "\n",
    "unit_list = [(k) for k in glider_names.keys()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5adbbb8a-9fe0-4c70-9cae-7cdf0d8601bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unit_398_20220308_bin10m.nc\n"
     ]
    }
   ],
   "source": [
    "for uname in unit_list:\n",
    "    fname = uname+'*_data_o2.nc'\n",
    "    \n",
    "    # Extract a list with the names of existing interim data files\n",
    "    existing_files = glob.glob(cat_interim_path(fname))\n",
    "    \n",
    "    # Check whether there are any files\n",
    "    if len(existing_files) > 0:\n",
    "        # Extract the most recent filename\n",
    "        existing_files = sorted(existing_files)\n",
    "        latest_file = existing_files[-1]\n",
    "        \n",
    "        # Open the dataset\n",
    "        data_ds = xr.open_dataset(latest_file)\n",
    "         \n",
    "        if 0:\n",
    "            # Check whether a gridded file has already been created\n",
    "            # Not yet implemented\n",
    "            proc_files = glob.glob(cat_interim_path(fname))\n",
    "            if not len(proc_files) > 0:\n",
    "                print('No processed files for that glider')\n",
    "   \n",
    "        #--------------------------------------------------------------\n",
    "        # Grid data onto a regular pressure grid (intervals given by dp)\n",
    "        # - Grid data into a 2d matrix against profile index & pressure grid \n",
    "        #    NOTE: Gridding is rough and *not* science quality\n",
    "        # Saves output to 01-data/03-processed/*_bin10m.nc\n",
    "        #--------------------------------------------------------------\n",
    "        grid_ds = bin_dp(data_ds, data_ds.attrs['Serial number'], dp)\n",
    "        \n",
    "        #-------------------------\n",
    "        # Add extra vector coordinates\n",
    "        #--------------------\n",
    "        mtime = grid_ds.time.mean(dim='pressure').values\n",
    "        mlon = grid_ds.m_lon.mean(dim='pressure').values\n",
    "        mlat = grid_ds.m_lat.mean(dim='pressure').values\n",
    "\n",
    "        # Interpolate over lat and long values\n",
    "        divenum = grid_ds.divenum.values\n",
    "\n",
    "        # Lon\n",
    "        idxnan = (~np.isnan(mlon))\n",
    "        divenum_nonnan = divenum[idxnan]\n",
    "        mlon_nonnan = mlon[idxnan]\n",
    "        flon = interp1d(divenum_nonnan, mlon_nonnan,\n",
    "                        kind='linear', fill_value=\"extrapolate\")\n",
    "        mlon_full = flon(divenum)\n",
    "\n",
    "        # Lat\n",
    "        idxnan = (~np.isnan(mlat))\n",
    "        divenum_nonnan = divenum[idxnan]\n",
    "        mlat_nonnan = mlat[idxnan]\n",
    "        flat = interp1d(divenum_nonnan,mlat_nonnan,\n",
    "                        kind='linear', fill_value=\"extrapolate\")\n",
    "        mlat_full = flat(divenum)\n",
    "\n",
    "        # Calculate distances from the interpolated lat/lon positions\n",
    "        dist_km = gsw.distance(mlat_full, mlon_full, 0, axis=0)/1000\n",
    "        dist_km_pad = np.append(0, dist_km)\n",
    "        # Cumsum is a problem, need to do something about NaN?\n",
    "        dist_along_track = np.cumsum(dist_km_pad)\n",
    "\n",
    "        # Create data array versions\n",
    "        DAT_2 = xr.DataArray(dist_along_track, \n",
    "                             coords={\"divenum\": grid_ds.divenum},\n",
    "                             attrs=dict(long_name=\"Distance\", units=\"km\"))\n",
    "        TIME_2 = xr.DataArray(mtime, \n",
    "                              coords={\"divenum\": grid_ds.divenum},\n",
    "                             attrs=dict(long_name=\"Date\"))\n",
    "        LAT_2 = xr.DataArray(mlat_full, \n",
    "                             coords={\"divenum\": grid_ds.divenum},\n",
    "                            attrs=dict(long_name=\"Latitude\"))\n",
    "        LON_2 = xr.DataArray(mlon_full, \n",
    "                             coords={\"divenum\": grid_ds.divenum},\n",
    "                            attrs=dict(long_name=\"Longitude\"))\n",
    "\n",
    "\n",
    "\n",
    "        grid_ds[\"dist_along_track\"] = DAT_2\n",
    "        grid_ds[\"timevec\"] = TIME_2\n",
    "        grid_ds[\"lonvec\"] = LON_2\n",
    "        grid_ds[\"latvec\"] = LAT_2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Change the variables to coordinates\n",
    "        grid_ds = grid_ds.set_coords(['dist_along_track','timevec',\n",
    "                                      'lonvec','latvec'])\n",
    "\n",
    "        #-------------------------------------------------\n",
    "        # Save gridded    \n",
    "        #-------------------------------------------------\n",
    "        data_ds.close()\n",
    "\n",
    "        # Filename\n",
    "        uname = data_ds.attrs['Serial number']\n",
    "        maxtimestr = data_ds.attrs['End Time']\n",
    "        outfile = uname+'_'+maxtimestr+'_bin10m.nc'\n",
    "        print(outfile)\n",
    "        grid_ds.to_netcdf(cat_proc_path(outfile), mode='w')\n",
    "        grid_ds.close()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c132ebc2-43d4-4906-a4d6-2ff472444b54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a96cecf-7bff-415a-923e-cbcec9167151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46582a60-09ca-425d-bb70-e4a5687da9a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid398' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tmp\u001b[38;5;241m=\u001b[39m\u001b[43mgrid398\u001b[49m\u001b[38;5;241m.\u001b[39mtime\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpressure\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m grid398[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimevec\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tmp\n\u001b[1;32m      4\u001b[0m grid398\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grid398' is not defined"
     ]
    }
   ],
   "source": [
    "tmp=grid398.time.mean(dim='pressure')\n",
    "grid398[\"timevec\"] = tmp\n",
    "\n",
    "grid398"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15ababa6-874c-4568-8cbc-813cb22f2533",
   "metadata": {},
   "outputs": [],
   "source": [
    "presname = 'pressure_dbar'\n",
    "idxname = 'profile_index'\n",
    "u1 = data_ds\n",
    "unitname='unit_409'\n",
    "dp=10\n",
    "\n",
    "# Create a temporary time variable\n",
    "u1 = u1.assign(timevar=u1.time.astype('float'))\n",
    "\n",
    "# Extract an array of pressure and profile_index values\n",
    "pres = u1[presname].values\n",
    "prof_idx = u1[idxname].values\n",
    "\n",
    "# Compute the bins, evenly spaced between the surface and 1000m\n",
    "# ISSUE: Note the hardcoding of maximum pressure\n",
    "pmin = 0\n",
    "pmax = 1000\n",
    "nbins = int(round((pmax-pmin)/dp))\n",
    "bins10m = np.linspace(pmin, pmax, nbins+1)\n",
    "pres10m = np.linspace(pmin+dp/2, pmax-dp/2, nbins)\n",
    "\n",
    "# Get a unique list of all the dive numbers (whole *.0 - dive, and half *.5 - climb)\n",
    "divenum_vec = np.unique(u1[idxname].values)\n",
    "# Remove the nan values\n",
    "divenum_vec = divenum_vec[~np.isnan(divenum_vec)]\n",
    "\n",
    "# Updated to operate on all variables in the data array\n",
    "varlist = list(u1.keys())\n",
    "varlist.remove(idxname)\n",
    "varlist.remove(presname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9cf8f442-0602-41f4-92b3-38330ff47926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise an empty dictionary of variables\n",
    "myvars = dict()\n",
    "\n",
    "counter = 0\n",
    "for i in divenum_vec:\n",
    "    # Subselect the xarray dataset for the dive or climb indices only\n",
    "    u11 = u1.where(u1[idxname]==i, drop=True)\n",
    "\n",
    "    if len(u11[\"time\"])>1:\n",
    "        # Make sure there are non-NaN values\n",
    "         # Calculate the median of values within the bin\n",
    "        ddive = u11.groupby_bins(presname,bins10m, squeeze=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aafc1dce-7b49-4bcd-9b9d-1f1f95786edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388.5\n"
     ]
    }
   ],
   "source": [
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d902be9-7b46-460c-93ce-d1e9de7f7407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(u11[\"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3266698e-6e76-4c46-b7a9-a1fe44ba169b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_c2slocum",
   "language": "python",
   "name": "env_c2slocum"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
