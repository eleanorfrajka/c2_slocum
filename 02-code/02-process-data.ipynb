{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bef13aa9-7d26-44f2-a2d2-b85044532f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime \n",
    "from setdir import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e502cc90-8314-4bb6-b8fe-2b6f05619c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slocum gliders: Serial numbers\n",
    "unit_list = ['unit_398', 'unit_409']\n",
    "\n",
    "# Formatting string for date/time to use in filenaming\n",
    "time_strf = '%Y%m%d'\n",
    "\n",
    "# Name the file according to what date?\n",
    "# Currently implemented: Date file was created\n",
    "# Alternate option: end date of data record\n",
    "yyyymmdd = datetime.datetime.now().strftime(time_strf)\n",
    "\n",
    "# Time limits\n",
    "datestart = '2021-12-12'\n",
    "#tstart = time.mktime(datetime.datetime.strptime(datestart,'%Y-%m-%d').timetuple())\n",
    "tstart = pd.Timestamp('2021-12-12T00')\n",
    "\n",
    "# Initialise the figure directory\n",
    "figdir = create_figdir()\n",
    "\n",
    "font = {'family' : 'sans-serif',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 16}\n",
    "\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1f3dcd4-0a69-40e6-9fc0-75c977fe9683",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../01-data/01-raw/unit_398_20220124.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m infile \u001b[38;5;241m=\u001b[39m i\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39myyyymmdd\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      8\u001b[0m infile_with_path \u001b[38;5;241m=\u001b[39m cat_raw_path(infile)\n\u001b[0;32m----> 9\u001b[0m data_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfile_with_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m data_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data_df\u001b[38;5;241m.\u001b[39mtimestamp\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x:\n\u001b[1;32m     12\u001b[0m                                 datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mfromtimestamp(x\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.001\u001b[39m))\n\u001b[1;32m     13\u001b[0m data_df \u001b[38;5;241m=\u001b[39m data_df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/env_c2slocum/lib/python3.9/site-packages/pandas/io/pickle.py:196\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;124;03m>>> os.remove(\"./dummy.pkl\")\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    195\u001b[0m excs_to_catch \u001b[38;5;241m=\u001b[39m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[0;32m--> 196\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    203\u001b[0m \n\u001b[1;32m    204\u001b[0m     \u001b[38;5;66;03m# 1) try standard library Pickle\u001b[39;00m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[1;32m    210\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/env_c2slocum/lib/python3.9/site-packages/pandas/io/common.py:711\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    702\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    703\u001b[0m             handle,\n\u001b[1;32m    704\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    707\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    708\u001b[0m         )\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    710\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 711\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    712\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../01-data/01-raw/unit_398_20220124.pkl'"
     ]
    }
   ],
   "source": [
    "# Add a time column, add a pressure_dbar column, and trim the start (pre-deployment)\n",
    "# Converts to xarray before saving as a netcdf file in 02-interim\n",
    "count = 0\n",
    "# Process a pickle\n",
    "for i in unit_list:\n",
    "    count += 1\n",
    "    infile = i+'_'+yyyymmdd+'.pkl'\n",
    "    infile_with_path = cat_raw_path(infile)\n",
    "    data_df = pd.read_pickle(infile_with_path)\n",
    "\n",
    "    data_df['time'] = data_df.timestamp.apply(lambda x:\n",
    "                                    datetime.datetime.fromtimestamp(x*0.001))\n",
    "    data_df = data_df.drop(columns='timestamp')\n",
    "    # Cut data to post deployment\n",
    "    data_df_2021 = data_df[data_df.time>=tstart].copy()\n",
    "    \n",
    "    # Change pressure from bars to dbars\n",
    "    data_df_2021['pressure_dbar'] =  data_df_2021.sci_water_pressure * 10\n",
    "    \n",
    "    # Remove negative salinities\n",
    "    df1 = data_df_2021['derived_salinity']\n",
    "    df2 = df1.where(df1>0)\n",
    "    data_df_2021['derived_salinity'] = df2\n",
    "        \n",
    "    # Prepare to convert to xarray\n",
    "    data_df2 = data_df_2021\n",
    "    data_df2 = data_df2.set_index(\"time\")\n",
    "    data_df2 = data_df2.drop(columns=\"sci_water_pressure\")\n",
    "    \n",
    "    # Convert to xarray\n",
    "    ds_2021 = data_df2.to_xarray()\n",
    "\n",
    "    # Set some attributes\n",
    "    project_name = 'TERIFIC'\n",
    "    institution_name = 'National Oceanography Centre, UK'\n",
    "    maxtimestr = pd.to_datetime(ds_2021.time.values.max()).strftime(time_strf)\n",
    "\n",
    "    # Create a dictionary of attributes\n",
    "    attr_dict = {\"Platform\": \"Slocum glider\",\n",
    "                 \"End Time\": maxtimestr,\n",
    "                 \"Project\": project_name,\n",
    "                 \"Institution\": institution_name,\n",
    "                 \"Date created\": yyyymmdd, \n",
    "                 \"Serial number\": i,\n",
    "                 \n",
    "            }\n",
    "\n",
    "    ds_2021.assign_attrs(attr_dict)\n",
    "\n",
    "    # Save a netcdf file\n",
    "    outfile = i+'_'+maxtimestr+'_edit.nc'\n",
    "    outfile_with_path = cat_interim_path(outfile)\n",
    "    \n",
    "    ds_2021.to_netcdf(outfile_with_path)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "580a0004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickle for position and convert to xarray dataset.\n",
    "count = 0\n",
    "# Process a pickle\n",
    "for i in unit_list:\n",
    "    count += 1\n",
    "    infile = i+'_positions_'+yyyymmdd+'.pkl'\n",
    "    infile_with_path = cat_raw_path(infile)\n",
    "    data_df = pd.read_pickle(infile_with_path)\n",
    "\n",
    "    # Prepare to convert to xarray\n",
    "    data_df2 = data_df\n",
    "    data_df2[\"time\"] = data_df[\"time\"].astype('datetime64').dt.round('1s')\n",
    "    data_df2[\"time_received\"] = data_df[\"time\"].astype('datetime64').dt.round('1s')\n",
    "    data_df2 = data_df2.set_index(\"time\")\n",
    "    data_df2 = data_df2.drop(columns=\"source\")\n",
    "    ds_2021 = data_df2.to_xarray()\n",
    "\n",
    "    # Set some attributes\n",
    "    project_name = 'TERIFIC'\n",
    "    institution_name = 'National Oceanography Centre, UK'\n",
    "    maxtimestr = pd.to_datetime(ds_2021.time.values.max()).strftime(time_strf)\n",
    "\n",
    "    # Create a dictionary of attributes\n",
    "    attr_dict = {\"Platform\": \"Slocum glider\",\n",
    "                 \"End Time\": maxtimestr,\n",
    "                 \"Project\": project_name,\n",
    "                 \"Institution\": institution_name,\n",
    "                 \"Date created\": yyyymmdd, \n",
    "                 \"Serial number\": i,\n",
    "                 \n",
    "            }\n",
    "\n",
    "    ds_2021.assign_attrs(attr_dict)\n",
    "\n",
    "\n",
    "    # Save a netcdf file\n",
    "    outfile = i+'_position_'+maxtimestr+'.nc'\n",
    "    outfile_with_path = cat_interim_path(outfile)\n",
    "    \n",
    "    ds_2021.to_netcdf(outfile_with_path, 'w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbb0f2e-c647-49a1-b39c-4966ea7b9d84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_c2slocum",
   "language": "python",
   "name": "env_c2slocum"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
