{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "428ca4b2-e930-4925-ba9e-7d77d5fcd896",
   "metadata": {},
   "source": [
    "# Notebook to test edits for process_glider_data.py file\n",
    "\n",
    "THIS IS ONLY FOR TESTING CODE.  For operational use, start with **process_glider_data.py**\n",
    "\n",
    "Processes slocum glider downloaded from C2\n",
    "\n",
    "1. Works locally on the downloaded raw netcdf files.\n",
    "2. Assign profile index, separate dives and climbs\n",
    "3. Calculate oxygen\n",
    "\n",
    "FEATURE TO ADD: \n",
    "- Will probably need to calculate TEOS-10 variables\n",
    "- Any handling of wetlabs data?\n",
    "\n",
    "Runs offline, using the netcdf files created in download_data.py\n",
    "\n",
    "Next step: process_glider_tseries.py which works on the raw data and calculates \n",
    "some things (profile index, oxygen concentration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f67044f0-59d7-4f4b-8267-405124a756d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "import glob\n",
    "import datetime as dt\n",
    "# Own packages of code\n",
    "from setdir import *\n",
    "from parseglider import *\n",
    "from calc_oxy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cdfed1b-02ee-404d-874f-9ee2dcbbd9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choice of grid interval (pressure in dbar)\n",
    "dp=10\n",
    "\n",
    "## CHANGE TO A CONFIG FILE WITH USER DEFINABLE PARAMETERS\n",
    "# Slocum gliders: A dictionary with the key as the serial number ('unit_398') \n",
    "# and then the plain text name, \"Churchill\"\n",
    "glider_names = {\n",
    "    'unit_398': 'Churchill',\n",
    "    'unit_409': 'Grease',\n",
    "}\n",
    "\n",
    "sensor_sn = {\n",
    "    'unit_398': {\"optode SN\": \"232\"},\n",
    "    'unit_409': {\"optode SN\": \"268\"},\n",
    "}\n",
    "# Dictionary keys MUST match the serial number format used in the API.  \n",
    "\n",
    "\n",
    "# Choose name for new DataArrays to index the profiles:\n",
    "idxname = 'profile_index'\n",
    "# Choose name for new DataArray for pressure in dbar:\n",
    "presname = 'pressure_dbar'\n",
    "\n",
    "# List of glider serial numbers for API\n",
    "unit_list = [(k) for k in glider_names.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "789d5d34-7756-4822-b955-b5236bbd8913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Changing idive, idx was 330 is now  329\n",
      "51. Changing iclimb, idx was 2932, is now 2933\n",
      "56. Changing idive, idx was 3355 is now  3354\n",
      "140. Changing idive, idx was 28836 is now  28835\n",
      "157. Changing iclimb, idx was 33897, is now 33898\n",
      "161. Changing iclimb, idx was 35153, is now 35154\n",
      "162. Changing iclimb, idx was 35516, is now 35517\n",
      "202. Changing idive, idx was 47886 is now  47885\n",
      "275. Changing iclimb, idx was 70150, is now 70151\n",
      "285. Changing iclimb, idx was 73200, is now 73201\n",
      "302. Changing iclimb, idx was 78491, is now 78492\n",
      "353. Changing iclimb, idx was 94536, is now 94537\n",
      "365. Changing iclimb, idx was 98577, is now 98578\n",
      "380. Changing iclimb, idx was 102790, is now 102791\n",
      "432. Changing iclimb, idx was 118860, is now 118861\n",
      "438. Changing iclimb, idx was 120881, is now 120882\n",
      "7. Changing iclimb, idx was 366, is now 367\n",
      "54. Changing idive, idx was 3298 is now  3297\n",
      "68. Changing iclimb, idx was 5878, is now 5879\n",
      "222. Changing iclimb, idx was 40325, is now 40326\n",
      "229. Changing iclimb, idx was 42847, is now 42848\n",
      "236. Changing iclimb, idx was 45386, is now 45387\n",
      "240. Changing iclimb, idx was 46699, is now 46700\n",
      "299. Changing iclimb, idx was 66260, is now 66261\n",
      "302. Changing iclimb, idx was 66886, is now 66887\n",
      "332. Changing iclimb, idx was 76952, is now 76953\n",
      "342. Changing iclimb, idx was 80089, is now 80090\n",
      "409. Changing iclimb, idx was 101128, is now 101129\n",
      "412. Changing iclimb, idx was 101850, is now 101851\n",
      "415. Changing iclimb, idx was 102573, is now 102574\n",
      "420. Changing iclimb, idx was 103480, is now 103481\n",
      "424. Changing iclimb, idx was 104275, is now 104276\n",
      "435. Changing idive, idx was 106457 is now  106456\n",
      "449. Changing iclimb, idx was 109851, is now 109852\n",
      "452. Changing iclimb, idx was 110568, is now 110569\n",
      "462. Changing iclimb, idx was 112965, is now 112966\n",
      "471. Changing iclimb, idx was 115121, is now 115122\n",
      "485. Changing iclimb, idx was 118660, is now 118661\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------\n",
    "# DATA PROCESSING:\n",
    "# - Assign a profile index to separate dives and climbs\n",
    "#\n",
    "# Save new files to 01-data/01-raw/ as\n",
    "#   UNIT_YYYYMMDD_data.nc for the full data as a vector\n",
    "#--------------------------------------------------------------\n",
    "for uname in unit_list:\n",
    "    fname = uname+'*_data.nc'\n",
    "    \n",
    "    # Extract a list with the names of existing raw data files\n",
    "    existing_files = glob.glob(cat_raw_path(fname))\n",
    "\n",
    "    # Check whether there are any files\n",
    "    if len(existing_files) > 0:\n",
    "        # Extract the end date from the filename\n",
    "        existing_files = sorted(existing_files)\n",
    "        latest_file = existing_files[-1]\n",
    "        \n",
    "        # Open the dataset\n",
    "        data_ds = xr.open_dataset(latest_file)\n",
    "        \n",
    "        #--------------------------------------------------------------\n",
    "        # Assign profile index (separates dives and climbs)\n",
    "        # This should actually be moved to process_data.py\n",
    "        #--------------------------------------------------------------\n",
    "        # where 20.0 means the twentieth dive (downward profile)\n",
    "        # and 20.5 is the twentieth climb (upward profile)\n",
    "        data_ds, _, _ = dive_index(data_ds, presname, idxname)\n",
    "                 \n",
    "        #--------------------------------------------------------------\n",
    "        # Calculate oxygen \n",
    "        #--------------------------------------------------------------\n",
    "        sensorsn1 = sensor_sn[uname]\n",
    "        data_ds = data_ds.assign_attrs(sensorsn1)\n",
    "        data_ds = calc_o2conc_cal(data_ds)\n",
    "        fname2 = latest_file[0:-3]+'_o2.nc'\n",
    "        fname2 = os.path.basename(fname2)\n",
    "        \n",
    "        print('Saving to '+cat_interim_path(fname2))\n",
    "        data_ds.to_netcdf(cat_interim_path(fname2), mode='w')\n",
    "        data_ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38d50eb4-1354-44e5-97b9-09d8b0f71fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# At some point, will likely need to calculate TEOS10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2540824e-1dce-4b63-8c48-b3b0b61cda84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is only here a second time for troubleshooting, since the gridding\n",
    "# process is time consuming and if something goes wrong, it's best separate\n",
    "# the two different vehicles\n",
    "glider_names = {\n",
    "    'unit_398': 'Churchill',\n",
    "}\n",
    "\n",
    "\n",
    "glider_names = {\n",
    "    'unit_409': 'Grease',\n",
    "}\n",
    "\n",
    "unit_list = [(k) for k in glider_names.keys()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5adbbb8a-9fe0-4c70-9cae-7cdf0d8601bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving processed to ../01-data/03-processed/unit_409_20220311_bin10m.nc\n"
     ]
    }
   ],
   "source": [
    "# Grid the data and make some calculations on the gridded data (MLD)\n",
    "for uname in unit_list:\n",
    "    fname = uname+'*_data_o2.nc'\n",
    "    \n",
    "    # Extract a list with the names of existing interim data files\n",
    "    existing_files = glob.glob(cat_interim_path(fname))\n",
    "    \n",
    "    # Check whether there are any files\n",
    "    if len(existing_files) > 0:\n",
    "        # Extract the most recent filename\n",
    "        existing_files = sorted(existing_files)\n",
    "        latest_file = existing_files[-1]\n",
    "        \n",
    "        # Open the dataset\n",
    "        data_ds = xr.open_dataset(latest_file)\n",
    "         \n",
    "        if 0:\n",
    "            # Check whether a gridded file has already been created\n",
    "            # Not yet implemented\n",
    "            proc_files = glob.glob(cat_interim_path(fname))\n",
    "            if not len(proc_files) > 0:\n",
    "                print('No processed files for that glider')\n",
    "   \n",
    "        #--------------------------------------------------------------\n",
    "        # Grid data onto a regular pressure grid (intervals given by dp)\n",
    "        # - Grid data into a 2d matrix against profile index & pressure grid \n",
    "        #    NOTE: Gridding is rough and *not* science quality\n",
    "        #--------------------------------------------------------------\n",
    "        grid_ds = bin_dp(data_ds, data_ds.attrs['Serial number'], dp)\n",
    "       \n",
    "        # EFW: I think closing these helps with file management & permission \n",
    "        # denied problems? \n",
    "        data_ds.close()\n",
    "\n",
    "\n",
    "        #------------------------------------------\n",
    "        # ADD EXTRA COORDINATES (length divenum)\n",
    "        #------------------------------------------\n",
    "        # Simplifies plotting later to plot against time or distance\n",
    "        mtime = grid_ds.time.mean(dim='pressure').values\n",
    "        mlon = grid_ds.m_lon.mean(dim='pressure').values\n",
    "        mlat = grid_ds.m_lat.mean(dim='pressure').values\n",
    "\n",
    "        # Interpolate over lat and long values\n",
    "        divenum = grid_ds.divenum.values\n",
    "\n",
    "        # Lon\n",
    "        idxnan = (~np.isnan(mlon))\n",
    "        divenum_nonnan = divenum[idxnan]\n",
    "        mlon_nonnan = mlon[idxnan]\n",
    "        flon = interp1d(divenum_nonnan, mlon_nonnan,\n",
    "                        kind='linear', fill_value=\"extrapolate\")\n",
    "        mlon_full = flon(divenum)\n",
    "\n",
    "        # Lat\n",
    "        idxnan = (~np.isnan(mlat))\n",
    "        divenum_nonnan = divenum[idxnan]\n",
    "        mlat_nonnan = mlat[idxnan]\n",
    "        flat = interp1d(divenum_nonnan,mlat_nonnan,\n",
    "                        kind='linear', fill_value=\"extrapolate\")\n",
    "        mlat_full = flat(divenum)\n",
    "\n",
    "        # Calculate distances from the interpolated lat/lon positions\n",
    "        dist_km = gsw.distance(mlat_full, mlon_full, 0, axis=0)/1000\n",
    "        dist_km_pad = np.append(0, dist_km)\n",
    "        # Cumsum is a problem, need to do something about NaN?\n",
    "        dist_along_track = np.cumsum(dist_km_pad)\n",
    "\n",
    "        # Create data array versions\n",
    "        DAT_2 = xr.DataArray(dist_along_track, \n",
    "                             coords={\"divenum\": grid_ds.divenum},\n",
    "                             attrs=dict(long_name=\"Distance\", units=\"km\"))\n",
    "        TIME_2 = xr.DataArray(mtime, \n",
    "                              coords={\"divenum\": grid_ds.divenum},\n",
    "                             attrs=dict(long_name=\"Date\"))\n",
    "        LAT_2 = xr.DataArray(mlat_full, \n",
    "                             coords={\"divenum\": grid_ds.divenum},\n",
    "                            attrs=dict(long_name=\"Latitude\"))\n",
    "        LON_2 = xr.DataArray(mlon_full, \n",
    "                             coords={\"divenum\": grid_ds.divenum},\n",
    "                            attrs=dict(long_name=\"Longitude\"))\n",
    "\n",
    "\n",
    "\n",
    "        grid_ds[\"dist_along_track\"] = DAT_2\n",
    "        grid_ds[\"timevec\"] = TIME_2\n",
    "        grid_ds[\"lonvec\"] = LON_2\n",
    "        grid_ds[\"latvec\"] = LAT_2\n",
    "\n",
    "        # Change the variables to coordinates\n",
    "        grid_ds = grid_ds.set_coords(['dist_along_track','timevec',\n",
    "                                      'lonvec','latvec'])\n",
    "\n",
    "        #-------------------------------------------------\n",
    "        # Calculate mixed layer depth\n",
    "        #-------------------------------------------------\n",
    "        grid_ds = calc_MLD(grid_ds)\n",
    "\n",
    "        #-------------------------------------------------\n",
    "        # Save gridded to 01-data/03-processed/*_bin10m.nc\n",
    "        #-------------------------------------------------\n",
    "        # Filename as 'unit_409_YYYYMMDD_bin10m.nc'\n",
    "        uname = data_ds.attrs['Serial number']\n",
    "        maxtimestr = data_ds.attrs['End Time']\n",
    "        outfile = uname+'_'+maxtimestr+'_bin10m.nc'\n",
    "        print('Saving processed to '+cat_proc_path(outfile))\n",
    "        grid_ds.to_netcdf(cat_proc_path(outfile), mode='w')\n",
    "        \n",
    "        # EFW: I think closing these helps with file management & permission \n",
    "        # denied problems? \n",
    "        grid_ds.close()     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1317a69f-faf5-455a-be99-17a0fe5f6126",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_c2slocum",
   "language": "python",
   "name": "env_c2slocum"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
