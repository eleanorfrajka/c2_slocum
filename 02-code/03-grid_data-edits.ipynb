{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "428ca4b2-e930-4925-ba9e-7d77d5fcd896",
   "metadata": {},
   "source": [
    "# Notebook to test edits for grid_glider_data.py file\n",
    "\n",
    "THIS IS ONLY FOR TESTING CODE.  For operational use, start with **grid_glider_data.py**\n",
    "\n",
    "Script to grid glider (slocum) data and make various calculations on the profiles.\n",
    "\n",
    "1. Works locally on the processed netcdf glider time series *o2.nc\n",
    "2. Grid glider data\n",
    "3. Calculate MLD\n",
    "\n",
    "Runs offline, using the netcdf files created in process_glider_tseries.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f67044f0-59d7-4f4b-8267-405124a756d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "import glob\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "# Own packages of code\n",
    "from setdir import *\n",
    "from parseglider import *\n",
    "from calc_glider import *\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cdfed1b-02ee-404d-874f-9ee2dcbbd9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choice of grid interval (pressure in dbar)\n",
    "dp=10\n",
    "\n",
    "## CHANGE TO A CONFIG FILE WITH USER DEFINABLE PARAMETERS\n",
    "# Slocum gliders: A dictionary with the key as the serial number ('unit_398') \n",
    "# and then the plain text name, \"Churchill\"\n",
    "glider_names = {\n",
    "    'unit_398': 'Churchill',\n",
    "    'unit_409': 'Grease',\n",
    "}\n",
    "\n",
    "# List of glider serial numbers for API\n",
    "unit_list = [(k) for k in glider_names.keys()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5adbbb8a-9fe0-4c70-9cae-7cdf0d8601bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving processed to ../01-data/03-processed/unit_409_20220311_bin10m.nc\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------------------------\n",
    "# GRIDDING DATA AND CALCULATIONS ON THE GRIDDED DATA \n",
    "# Grid the data and make some calculations on the gridded data (MLD)\n",
    "#----------------------------------------------------------------------\n",
    "for uname in unit_list:\n",
    "    fname = uname+'*_data_o2.nc'\n",
    "    \n",
    "    # Extract a list with the names of existing interim data files\n",
    "    existing_files = glob.glob(cat_interim_path(fname))\n",
    "    \n",
    "    # Check whether there are any files\n",
    "    if len(existing_files) > 0:\n",
    "        # Extract the most recent filename\n",
    "        existing_files = sorted(existing_files)\n",
    "        latest_file = existing_files[-1]\n",
    "        \n",
    "        # Open the dataset\n",
    "        data_ds = xr.open_dataset(latest_file)\n",
    "         \n",
    "        if 0:\n",
    "            # Check whether a gridded file has already been created\n",
    "            # Not yet implemented\n",
    "            proc_files = glob.glob(cat_interim_path(fname))\n",
    "            if not len(proc_files) > 0:\n",
    "                print('No processed files for that glider')\n",
    "   \n",
    "        #--------------------------------------------------------------\n",
    "        # Grid data onto a regular pressure grid (intervals given by dp)\n",
    "        # - Grid data into a 2d matrix against profile index & pressure grid \n",
    "        #    NOTE: Gridding is rough and *not* science quality\n",
    "        #--------------------------------------------------------------\n",
    "        grid_ds = bin_dp(data_ds, data_ds.attrs['Serial number'], dp)\n",
    "       \n",
    "        # EFW: I think closing these helps with file management & permission \n",
    "        # denied problems? \n",
    "        data_ds.close()\n",
    "\n",
    "\n",
    "        #------------------------------------------\n",
    "        # ADD EXTRA COORDINATES (length divenum)\n",
    "        #------------------------------------------\n",
    "        # Simplifies plotting later to plot against time or distance\n",
    "        mtime = grid_ds.time.mean(dim='pressure').values\n",
    "        mlon = grid_ds.m_lon.mean(dim='pressure').values\n",
    "        mlat = grid_ds.m_lat.mean(dim='pressure').values\n",
    "\n",
    "        # Interpolate over lat and long values\n",
    "        divenum = grid_ds.divenum.values\n",
    "\n",
    "        # Lon\n",
    "        idxnan = (~np.isnan(mlon))\n",
    "        divenum_nonnan = divenum[idxnan]\n",
    "        mlon_nonnan = mlon[idxnan]\n",
    "        flon = interp1d(divenum_nonnan, mlon_nonnan,\n",
    "                        kind='linear', fill_value=\"extrapolate\")\n",
    "        mlon_full = flon(divenum)\n",
    "\n",
    "        # Lat\n",
    "        idxnan = (~np.isnan(mlat))\n",
    "        divenum_nonnan = divenum[idxnan]\n",
    "        mlat_nonnan = mlat[idxnan]\n",
    "        flat = interp1d(divenum_nonnan,mlat_nonnan,\n",
    "                        kind='linear', fill_value=\"extrapolate\")\n",
    "        mlat_full = flat(divenum)\n",
    "\n",
    "        # Calculate distances from the interpolated lat/lon positions\n",
    "        dist_km = gsw.distance(mlat_full, mlon_full, 0, axis=0)/1000\n",
    "        dist_km_pad = np.append(0, dist_km)\n",
    "        # Cumsum is a problem, need to do something about NaN?\n",
    "        dist_along_track = np.cumsum(dist_km_pad)\n",
    "\n",
    "        # Create data array versions\n",
    "        DAT_2 = xr.DataArray(dist_along_track, \n",
    "                             coords={\"divenum\": grid_ds.divenum},\n",
    "                             attrs=dict(long_name=\"Distance\", units=\"km\"))\n",
    "        TIME_2 = xr.DataArray(mtime, \n",
    "                              coords={\"divenum\": grid_ds.divenum},\n",
    "                             attrs=dict(long_name=\"Date\"))\n",
    "        LAT_2 = xr.DataArray(mlat_full, \n",
    "                             coords={\"divenum\": grid_ds.divenum},\n",
    "                            attrs=dict(long_name=\"Latitude\"))\n",
    "        LON_2 = xr.DataArray(mlon_full, \n",
    "                             coords={\"divenum\": grid_ds.divenum},\n",
    "                            attrs=dict(long_name=\"Longitude\"))\n",
    "\n",
    "\n",
    "\n",
    "        grid_ds[\"dist_along_track\"] = DAT_2\n",
    "        grid_ds[\"timevec\"] = TIME_2\n",
    "        grid_ds[\"lonvec\"] = LON_2\n",
    "        grid_ds[\"latvec\"] = LAT_2\n",
    "\n",
    "        # Change the variables to coordinates\n",
    "        grid_ds = grid_ds.set_coords(['dist_along_track','timevec',\n",
    "                                      'lonvec','latvec'])\n",
    "\n",
    "        #-------------------------------------------------\n",
    "        # Calculate mixed layer depth\n",
    "        #-------------------------------------------------\n",
    "        grid_ds = calc_MLD(grid_ds)\n",
    "\n",
    "        #-------------------------------------------------\n",
    "        # Save gridded to 01-data/03-processed/*_bin10m.nc\n",
    "        #-------------------------------------------------\n",
    "        # Filename as 'unit_409_YYYYMMDD_bin10m.nc'\n",
    "        uname = data_ds.attrs['Serial number']\n",
    "        maxtimestr = data_ds.attrs['End Time']\n",
    "        outfile = uname+'_'+maxtimestr+'_bin10m.nc'\n",
    "        print('Saving processed to '+cat_proc_path(outfile))\n",
    "        grid_ds.to_netcdf(cat_proc_path(outfile), mode='w')\n",
    "        \n",
    "        # EFW: I think closing these helps with file management & permission \n",
    "        # denied problems? \n",
    "        grid_ds.close()     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1317a69f-faf5-455a-be99-17a0fe5f6126",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_c2slocum",
   "language": "python",
   "name": "env_c2slocum"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
